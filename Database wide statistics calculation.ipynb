{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate stastistics for an entire database and sectors within the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Step : calculating indicators for each {activity|impact method}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import os\n",
    "\n",
    "#MC_results_dict={act:{ic_name:[MC_results]}} as the output of MC_multi_impact_entire_DB()\n",
    "\n",
    "#Stored MC results in HDF5 are np array 1d which size=# iteration\n",
    "#and stored like: Uncertainty LCI 1 LCIA 1/ActKey/impact method name\n",
    "\n",
    "\n",
    "\n",
    "def calculating_endpoint_sum(hdf5_file_MC_LCA_results,hdf5_file_MC_statistics):\n",
    "    \n",
    "    \n",
    "    for uncertainty_level in hdf5_file_MC_LCA_results.items():\n",
    "        \n",
    "        if 'lci_iteration_name_list' not in uncertainty_level[0]:\n",
    "\n",
    "            for act in uncertainty_level[1].items():                    \n",
    "                \n",
    "                for impact_method in act[1].items():\n",
    "                    \n",
    "                    #If endpoint names are the second name in impact method tuples (...,...,...)\n",
    "                    endpoint_name='{},{})'.format(impact_method[0].split(',', 3)[0],impact_method[0].split(',', 3)[1])\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    #If endpoint names are the first name in impact method tuples (...,...,...)\n",
    "                    #endpoint_name=impact_method[0].rsplit(',', 2)[0]+')'\n",
    "                    \n",
    "                    endpoint_group_path='/{}/{}/{}'.format(uncertainty_level[0],act[0],endpoint_name)\n",
    "                    \n",
    "                    contribution_to_add=impact_method[1][()]\n",
    "                    \n",
    "                    try:\n",
    "                        endpoint_sum_dataset=hdf5_file_MC_statistics['{}/endpoint_sum'.format(endpoint_group_path)]\n",
    "                        endpoint_sum_dataset[...]=endpoint_sum_dataset[()]+contribution_to_add\n",
    "                        \n",
    "                    except:\n",
    "                        hdf5_file_MC_statistics.create_dataset('{}/endpoint_sum'.format(endpoint_group_path),data=contribution_to_add)\n",
    "                        \n",
    "    return;\n",
    "\n",
    "\n",
    "\n",
    "def sensivity_index_1st(Y,X,bin_size=50):\n",
    "    \n",
    "    #Gathering Y and X\n",
    "    pairs=np.column_stack((Y,X))\n",
    "    \n",
    "    \n",
    "    #Sorting by X ascending\n",
    "    pairs=pairs[pairs[:, 1].argsort()]\n",
    "    \n",
    "    \n",
    "    #Number of bins\n",
    "    if Y.size%bin_size != 0:\n",
    "        print(\"bin_size should be adjusted to be a multiple of Y size\")\n",
    "        return;\n",
    "    \n",
    "    if bin_size%int(bin_size) != 0:\n",
    "        print(\"bin_size should be an integer\")\n",
    "        return;\n",
    "    \n",
    "    bins=int(Y.size/bin_size)\n",
    "    bin_size=int(bin_size)\n",
    "    \n",
    "    \n",
    "    #Calculating mean for each bin\n",
    "    data=pairs[:,0]\n",
    "    data=np.reshape(data,(bins,bin_size))\n",
    "    bin_means=np.mean(data, axis=1)\n",
    "    \n",
    "    \n",
    "    #sensivity_index_1st\n",
    "    si_1st=np.var(bin_means)/np.var(Y)\n",
    "    \n",
    "    return si_1st;\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#MC_results_dict={act_key:{ic_name:[MC_results]}} as the output of MC_multi_impact_entire_DB()\n",
    "\n",
    "def calculating_endpoint_stats_indicators(hdf5_file_MC_LCA_results,hdf5_file_MC_statistics,bin_size):\n",
    "  \n",
    "    sum_spear_corr_endpoint={}\n",
    "    \n",
    "    endpoint_name_list=[]\n",
    "    \n",
    "    for uncertainty_level in hdf5_file_MC_LCA_results.items():\n",
    "\n",
    "        if 'lci_iteration_name_list' not in uncertainty_level[0]:\n",
    "\n",
    "            for act in uncertainty_level[1].items():                    \n",
    "\n",
    "                for impact_method in act[1].items():\n",
    "\n",
    "                    #If endpoint names are the second name in impact method tuples (...,...,...)\n",
    "                    endpoint_name='{},{})'.format(impact_method[0].split(',', 3)[0],impact_method[0].split(',', 3)[1])\n",
    "                    \n",
    "                    \n",
    "                    #If endpoint names are the first name in impact method tuples (...,...,...)\n",
    "                    #endpoint_name=impact_method[0].rsplit(',', 2)[0]+')'\n",
    "                    \n",
    "                    endpoint_group_path='/{}/{}/{}'.format(uncertainty_level[0],act[0],endpoint_name)\n",
    "                    \n",
    "                    stats_dict={}\n",
    "                    \n",
    "                    #Regular stats\n",
    "                    stats_dict['mean']=np.mean(impact_method[1])\n",
    "                    stats_dict['variance']=np.var(impact_method[1])\n",
    "                    stats_dict['std dev']=np.std(impact_method[1])\n",
    "                    stats_dict['minimum']=min(impact_method[1])\n",
    "                    stats_dict['maximum']=max(impact_method[1])\n",
    "                    stats_dict['2.5th percentile']=np.percentile(impact_method[1],2.5)\n",
    "                    stats_dict['25th percentile']=np.percentile(impact_method[1],25)\n",
    "                    stats_dict['median']=np.percentile(impact_method[1],50)\n",
    "                    stats_dict['75th percentile']=np.percentile(impact_method[1],75)\n",
    "                    stats_dict['97.5th percentile']=np.percentile(impact_method[1],97.5)\n",
    "                    stats_dict['number of iterations']=len(impact_method[1])\n",
    "\n",
    "                    #Stats to measure the dispersion\n",
    "                    stats_dict['MADM']=np.percentile(abs(impact_method[1]-stats_dict['median']),50)\n",
    "                    stats_dict['IQR']=stats_dict['75th percentile']-stats_dict['25th percentile']\n",
    "                    stats_dict['Spread']=stats_dict['maximum']-stats_dict['minimum']\n",
    "                    stats_dict['CI95']=stats_dict['97.5th percentile']-stats_dict['2.5th percentile']\n",
    "                    try:\n",
    "                        stats_dict['Quartile coeff of dispersion']=stats_dict['IQR']/(stats_dict['75th percentile']+stats_dict['25th percentile'])\n",
    "                    except:\n",
    "                        stats_dict['Quartile coeff of dispersion']='NA'\n",
    "                    try:\n",
    "                        stats_dict['CV']=stats_dict['std dev']/stats_dict['mean']\n",
    "                    except:\n",
    "                        stats_dict['CV']='NA'\n",
    "                    try:\n",
    "                        stats_dict['CV modified']=stats_dict['std dev']/np.sqrt((stats_dict['maximum']-stats_dict['mean'])*(stats_dict['mean']-stats_dict['minimum']))\n",
    "                    except:\n",
    "                        stats_dict['CV modified']='NA'\n",
    "                    try:\n",
    "                        stats_dict['CV robust']=stats_dict['MADM']/stats_dict['median']\n",
    "                    except:\n",
    "                        stats_dict['CV robust']='NA'\n",
    "                    try:\n",
    "                        stats_dict['IQR\\spread']=stats_dict['IQR']/(stats_dict['Spread'])\n",
    "                    except:\n",
    "                        stats_dict['IQR\\spread']='NA'\n",
    "                    try:\n",
    "                        stats_dict['IQR\\CI95']=stats_dict['IQR']/stats_dict['CI95']\n",
    "                    except:\n",
    "                        stats_dict['IQR\\CI95']='NA'\n",
    "\n",
    "\n",
    "                    #Statistics based on endpoint_sum  \n",
    "                    endpoint_sum=hdf5_file_MC_statistics['{}/endpoint_sum'.format(endpoint_group_path)]\n",
    "                    \n",
    "                    stats_dict['Spearmann rank correlation - coefficient']=stats.spearmanr(impact_method[1],endpoint_sum)[0]\n",
    "                    stats_dict['Spearmann rank correlation - pvalue']=stats.spearmanr(impact_method[1],endpoint_sum)[1]\n",
    "                    \n",
    "                    if np.isnan(stats_dict['Spearmann rank correlation - coefficient']):\n",
    "                        stats_dict['Spearmann rank correlation - coefficient']=0\n",
    "\n",
    "                    try:\n",
    "                        sum_spear_corr_endpoint[endpoint_name]=sum_spear_corr_endpoint[endpoint_name]+(stats_dict['Spearmann rank correlation - coefficient'])**2\n",
    "\n",
    "                    except:\n",
    "                        sum_spear_corr_endpoint[endpoint_name]=(stats_dict['Spearmann rank correlation - coefficient'])**2\n",
    "                    \n",
    "                    \n",
    "                    stats_dict['Sensitivity index 1st order - midpoint to endpoint']=sensivity_index_1st(Y=endpoint_sum,X=impact_method[1],bin_size=bin_size)\n",
    "                        \n",
    "                        \n",
    "                    #print(str(stats_dict['Spearmann rank correlation - coefficient'])+' with sum '+str(sum_spear_corr_endpoint[endpoint_name]))\n",
    "                    \n",
    "                    \n",
    "                    #Store values\n",
    "                    impact_method_group_path='/{}/{}/{}'.format(uncertainty_level[0],act[0],impact_method[0])\n",
    "                    \n",
    "                    for indicator in stats_dict.keys():\n",
    "                        try:\n",
    "                            hdf5_file_MC_statistics.create_dataset('{}/{}'.format(impact_method_group_path,indicator),data=stats_dict[indicator])\n",
    "                        except:\n",
    "                            hdf5_file_MC_statistics['{}/{}'.format(impact_method_group_path,indicator)][...]=stats_dict[indicator]\n",
    "                 \n",
    "                \n",
    "                for impact_method in act[1].items():\n",
    "                    \n",
    "                    #If endpoint names are the second name in impact method tuples (...,...,...)\n",
    "                    #endpoint_name='{})'.format(impact_method[0].rsplit(',', 1)[0])\n",
    "                    endpoint_name='{},{})'.format(impact_method[0].split(',', 3)[0],impact_method[0].split(',', 3)[1])\n",
    "                    \n",
    "                    #If endpoint names are the first name in impact method tuples (...,...,...)\n",
    "                    #endpoint_name=impact_method[0].rsplit(',', 2)[0]+')'\n",
    "                    \n",
    "                    impact_method_group_path='/{}/{}/{}'.format(uncertainty_level[0],act[0],impact_method[0])\n",
    "\n",
    "                    #Calculating Contribution To Variance\n",
    "                    stats_dict={}\n",
    "                    stats_dict['Spearmann CTV midpoint to endpoint']=(hdf5_file_MC_statistics['{}/Spearmann rank correlation - coefficient'.format(impact_method_group_path)][()])**2/sum_spear_corr_endpoint[endpoint_name]\n",
    "                    \n",
    "                    \n",
    "                    #Store values\n",
    "                    for indicator in stats_dict.keys():\n",
    "                        try:\n",
    "                            hdf5_file_MC_statistics.create_dataset('{}/{}'.format(impact_method_group_path,indicator),data=stats_dict[indicator])\n",
    "                        except:\n",
    "                            hdf5_file_MC_statistics['{}/{}'.format(impact_method_group_path,indicator)][...]=stats_dict[indicator]\n",
    "                    \n",
    "                for endpoint_name in sum_spear_corr_endpoint.keys():\n",
    "                    sum_spear_corr_endpoint[endpoint_name]=0\n",
    "                    \n",
    "                    endpoint_name_list.append(endpoint_name)\n",
    "                    endpoint_name_list=list(set(endpoint_name_list))\n",
    "                    \n",
    "                    \n",
    "    #Calculating Sensitivity index between uncertainty level for endpoint_sum                \n",
    "    for endpoint_name in endpoint_name_list:\n",
    "    \n",
    "        for uncertainty_level in hdf5_file_MC_LCA_results.items():\n",
    "\n",
    "            if ('lci_iteration_name_list' or 'LCI 1 LCIA 1') not in uncertainty_level[0]:\n",
    "\n",
    "                for act in uncertainty_level[1].items():\n",
    "\n",
    "                    endpoint_group_path='/{}/{}/{}'.format(uncertainty_level[0],act[0],endpoint_name)\n",
    "                    endpoint_sum=hdf5_file_MC_statistics['{}/endpoint_sum'.format(endpoint_group_path)]\n",
    "                    \n",
    "                    endpoint_11_group_path='/{}/{}/{}'.format('Uncertainty LCI 1 LCIA 1',act[0],endpoint_name)\n",
    "                    endpoint_sum_11=hdf5_file_MC_statistics['{}/endpoint_sum'.format(endpoint_group_path)]\n",
    "\n",
    "                    stats_dict={}\n",
    "                    stats_dict['Sensitivity index 1st order - endpoint between uncertainty level']=sensivity_index_1st(Y=endpoint_sum_11,X=endpoint_sum,bin_size=bin_size)\n",
    "                    \n",
    "                    #Store values\n",
    "                    for indicator in stats_dict.keys():\n",
    "                        try:\n",
    "                            hdf5_file_MC_statistics.create_dataset('{}/{}'.format(endpoint_group_path,indicator),data=stats_dict[indicator])\n",
    "                        except:\n",
    "                            hdf5_file_MC_statistics['{}/{}'.format(endpoint_group_path,indicator)][...]=stats_dict[indicator]\n",
    "        \n",
    "    return;\n",
    "\n",
    "\n",
    "def calculating_endpoint_stats_entire_database_aggregated_MC_results(hdf5_file_MC_LCA_results_path, dir_path_for_saving,bin_size):\n",
    "    \n",
    "    #Create and/or open the file for MC stats results\n",
    "    hdf5_file_MC_statistics=h5py.File(os.path.join(dir_path_for_saving,'MC_statistics_aggregated_results.hdf5'),'w-')\n",
    "    \n",
    "    #Open the MC LCA results file\n",
    "    hdf5_file_MC_LCA_results=h5py.File(hdf5_file_MC_LCA_results_path,'r')\n",
    "    \n",
    "    #Calculate stats --> only make sense if impact categories in hdf5_file_MC_LCA_results are endpoint per midpoint categories\n",
    "    calculating_endpoint_sum(hdf5_file_MC_LCA_results,hdf5_file_MC_statistics)\n",
    "    calculating_endpoint_stats_indicators(hdf5_file_MC_LCA_results,hdf5_file_MC_statistics,bin_size)\n",
    "    \n",
    "    #Close hdf5 files\n",
    "    hdf5_file_MC_statistics.close()\n",
    "    hdf5_file_MC_LCA_results.close()\n",
    "    \n",
    "    return;    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in sqrt\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\ipykernel_launcher.py:147: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\ipykernel_launcher.py:151: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\numpy\\lib\\function_base.py:3162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\numpy\\lib\\function_base.py:3163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\ipykernel_launcher.py:139: RuntimeWarning: invalid value encountered in float_scalars\n"
     ]
    }
   ],
   "source": [
    "hdf5_file_MC_LCA_results_path=r\"D:\\Dossiers professionnels\\Logiciels\\Brightway 2\\Test Dependant LCA Monte Carlo - test 3\\LCA_Dependant_Monte_Carlo_aggregated_results_ALL.hdf5\"\n",
    "dir_path_for_saving=\"D:\\Dossiers professionnels\\Logiciels\\Brightway 2\\Test Dependant LCA Monte Carlo - test 3\"\n",
    "\n",
    "bin_size=100\n",
    "calculating_endpoint_stats_entire_database_aggregated_MC_results(hdf5_file_MC_LCA_results_path, dir_path_for_saving,bin_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83333.25, 0.07817271246938956)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import numpy as np\n",
    "X=np.random.random(1000)\n",
    "Y=np.arange(1000)\n",
    "\n",
    "np.var(Y),np.var(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 489.06  470.76  530.52  584.16  467.08  479.86  475.88  497.58  511.6\n",
      "  448.78  612.68  505.88  479.9   504.64  547.54  480.06  510.24  504.32\n",
      "  472.92  416.54]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.022473641673641659"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sensivity_index_1st(Y,X,bin_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05561784,  0.67129819],\n",
       "       [ 0.57679289,  0.72835559],\n",
       "       [ 0.31340933,  0.14037702],\n",
       "       [ 0.74814291,  0.91584807],\n",
       "       [ 0.88762585,  0.83594971],\n",
       "       [ 0.68554716,  0.31560965],\n",
       "       [ 0.13855739,  0.22897577],\n",
       "       [ 0.90786571,  0.12950932],\n",
       "       [ 0.12784339,  0.86145301],\n",
       "       [ 0.86138512,  0.26797564],\n",
       "       [ 0.59398654,  0.21868958],\n",
       "       [ 0.74969962,  0.05711744],\n",
       "       [ 0.58615788,  0.91062249],\n",
       "       [ 0.55691427,  0.66998432],\n",
       "       [ 0.90220203,  0.1326723 ],\n",
       "       [ 0.39422025,  0.32362138],\n",
       "       [ 0.14578997,  0.61006975],\n",
       "       [ 0.90143821,  0.68433986],\n",
       "       [ 0.95925203,  0.25026719],\n",
       "       [ 0.10580314,  0.13249037],\n",
       "       [ 0.02712601,  0.37122594],\n",
       "       [ 0.65932062,  0.18573381],\n",
       "       [ 0.65247316,  0.19692277],\n",
       "       [ 0.07159735,  0.77451529],\n",
       "       [ 0.34124012,  0.75488842],\n",
       "       [ 0.94523225,  0.05757424],\n",
       "       [ 0.10180174,  0.58926531],\n",
       "       [ 0.90041107,  0.93174501],\n",
       "       [ 0.08721703,  0.52337353],\n",
       "       [ 0.64711205,  0.56566148],\n",
       "       [ 0.1443516 ,  0.19621696],\n",
       "       [ 0.47316729,  0.55080986],\n",
       "       [ 0.61375438,  0.61870992],\n",
       "       [ 0.99555302,  0.05914512],\n",
       "       [ 0.73860371,  0.7543226 ],\n",
       "       [ 0.24951643,  0.23582248],\n",
       "       [ 0.55005082,  0.20884611],\n",
       "       [ 0.26953218,  0.19889657],\n",
       "       [ 0.64690736,  0.09372956],\n",
       "       [ 0.14756861,  0.14668482],\n",
       "       [ 0.33992657,  0.11491249],\n",
       "       [ 0.21832913,  0.91553868],\n",
       "       [ 0.45717413,  0.04067403],\n",
       "       [ 0.37345563,  0.79248378],\n",
       "       [ 0.91683535,  0.02062548],\n",
       "       [ 0.58640828,  0.44854065],\n",
       "       [ 0.68787272,  0.09714076],\n",
       "       [ 0.89275099,  0.99987134],\n",
       "       [ 0.95897061,  0.13483776],\n",
       "       [ 0.94451753,  0.39816592],\n",
       "       [ 0.71949026,  0.90777896],\n",
       "       [ 0.23636302,  0.20659357],\n",
       "       [ 0.27326587,  0.61146423],\n",
       "       [ 0.22617551,  0.20287346],\n",
       "       [ 0.66350068,  0.6563505 ],\n",
       "       [ 0.85329763,  0.85519832],\n",
       "       [ 0.13957594,  0.18581665],\n",
       "       [ 0.90554072,  0.27287824],\n",
       "       [ 0.9904141 ,  0.97264793],\n",
       "       [ 0.08914476,  0.5370497 ],\n",
       "       [ 0.36680882,  0.1081725 ],\n",
       "       [ 0.23546181,  0.18105396],\n",
       "       [ 0.37961668,  0.48597129],\n",
       "       [ 0.09595789,  0.26391548],\n",
       "       [ 0.46697896,  0.28166034],\n",
       "       [ 0.88950342,  0.72696275],\n",
       "       [ 0.17130699,  0.90090555],\n",
       "       [ 0.53337127,  0.96935042],\n",
       "       [ 0.41113054,  0.07184622],\n",
       "       [ 0.27071096,  0.80927623],\n",
       "       [ 0.15658305,  0.2835127 ],\n",
       "       [ 0.87998658,  0.28475516],\n",
       "       [ 0.79924637,  0.87471398],\n",
       "       [ 0.59465664,  0.08489839],\n",
       "       [ 0.74232022,  0.29105302],\n",
       "       [ 0.01933249,  0.06232794],\n",
       "       [ 0.00802643,  0.69826096],\n",
       "       [ 0.71617131,  0.7126932 ],\n",
       "       [ 0.08593361,  0.39057436],\n",
       "       [ 0.74941262,  0.61149865],\n",
       "       [ 0.30416718,  0.15524791],\n",
       "       [ 0.11753879,  0.02595412],\n",
       "       [ 0.83094588,  0.35246599],\n",
       "       [ 0.09985592,  0.85591995],\n",
       "       [ 0.69805797,  0.96562358],\n",
       "       [ 0.65340085,  0.93774178],\n",
       "       [ 0.65804783,  0.13448154],\n",
       "       [ 0.15303398,  0.22212472],\n",
       "       [ 0.27591197,  0.09048777],\n",
       "       [ 0.97554321,  0.0056588 ],\n",
       "       [ 0.20049751,  0.7394726 ],\n",
       "       [ 0.01988686,  0.57407918],\n",
       "       [ 0.94636011,  0.78701691],\n",
       "       [ 0.3984782 ,  0.96619787],\n",
       "       [ 0.49691032,  0.60702267],\n",
       "       [ 0.81656162,  0.79046895],\n",
       "       [ 0.91304535,  0.09239419],\n",
       "       [ 0.04801087,  0.69842534],\n",
       "       [ 0.81040828,  0.79120473],\n",
       "       [ 0.97286209,  0.32738002]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs=np.column_stack((Y,X))\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.97554321,  0.0056588 ],\n",
       "       [ 0.91683535,  0.02062548],\n",
       "       [ 0.11753879,  0.02595412],\n",
       "       [ 0.45717413,  0.04067403],\n",
       "       [ 0.74969962,  0.05711744],\n",
       "       [ 0.94523225,  0.05757424],\n",
       "       [ 0.99555302,  0.05914512],\n",
       "       [ 0.01933249,  0.06232794],\n",
       "       [ 0.41113054,  0.07184622],\n",
       "       [ 0.59465664,  0.08489839],\n",
       "       [ 0.27591197,  0.09048777],\n",
       "       [ 0.91304535,  0.09239419],\n",
       "       [ 0.64690736,  0.09372956],\n",
       "       [ 0.68787272,  0.09714076],\n",
       "       [ 0.36680882,  0.1081725 ],\n",
       "       [ 0.33992657,  0.11491249],\n",
       "       [ 0.90786571,  0.12950932],\n",
       "       [ 0.10580314,  0.13249037],\n",
       "       [ 0.90220203,  0.1326723 ],\n",
       "       [ 0.65804783,  0.13448154],\n",
       "       [ 0.95897061,  0.13483776],\n",
       "       [ 0.31340933,  0.14037702],\n",
       "       [ 0.14756861,  0.14668482],\n",
       "       [ 0.30416718,  0.15524791],\n",
       "       [ 0.23546181,  0.18105396],\n",
       "       [ 0.65932062,  0.18573381],\n",
       "       [ 0.13957594,  0.18581665],\n",
       "       [ 0.1443516 ,  0.19621696],\n",
       "       [ 0.65247316,  0.19692277],\n",
       "       [ 0.26953218,  0.19889657],\n",
       "       [ 0.22617551,  0.20287346],\n",
       "       [ 0.23636302,  0.20659357],\n",
       "       [ 0.55005082,  0.20884611],\n",
       "       [ 0.59398654,  0.21868958],\n",
       "       [ 0.15303398,  0.22212472],\n",
       "       [ 0.13855739,  0.22897577],\n",
       "       [ 0.24951643,  0.23582248],\n",
       "       [ 0.95925203,  0.25026719],\n",
       "       [ 0.09595789,  0.26391548],\n",
       "       [ 0.86138512,  0.26797564],\n",
       "       [ 0.90554072,  0.27287824],\n",
       "       [ 0.46697896,  0.28166034],\n",
       "       [ 0.15658305,  0.2835127 ],\n",
       "       [ 0.87998658,  0.28475516],\n",
       "       [ 0.74232022,  0.29105302],\n",
       "       [ 0.68554716,  0.31560965],\n",
       "       [ 0.39422025,  0.32362138],\n",
       "       [ 0.97286209,  0.32738002],\n",
       "       [ 0.83094588,  0.35246599],\n",
       "       [ 0.02712601,  0.37122594],\n",
       "       [ 0.08593361,  0.39057436],\n",
       "       [ 0.94451753,  0.39816592],\n",
       "       [ 0.58640828,  0.44854065],\n",
       "       [ 0.37961668,  0.48597129],\n",
       "       [ 0.08721703,  0.52337353],\n",
       "       [ 0.08914476,  0.5370497 ],\n",
       "       [ 0.47316729,  0.55080986],\n",
       "       [ 0.64711205,  0.56566148],\n",
       "       [ 0.01988686,  0.57407918],\n",
       "       [ 0.10180174,  0.58926531],\n",
       "       [ 0.49691032,  0.60702267],\n",
       "       [ 0.14578997,  0.61006975],\n",
       "       [ 0.27326587,  0.61146423],\n",
       "       [ 0.74941262,  0.61149865],\n",
       "       [ 0.61375438,  0.61870992],\n",
       "       [ 0.66350068,  0.6563505 ],\n",
       "       [ 0.55691427,  0.66998432],\n",
       "       [ 0.05561784,  0.67129819],\n",
       "       [ 0.90143821,  0.68433986],\n",
       "       [ 0.00802643,  0.69826096],\n",
       "       [ 0.04801087,  0.69842534],\n",
       "       [ 0.71617131,  0.7126932 ],\n",
       "       [ 0.88950342,  0.72696275],\n",
       "       [ 0.57679289,  0.72835559],\n",
       "       [ 0.20049751,  0.7394726 ],\n",
       "       [ 0.73860371,  0.7543226 ],\n",
       "       [ 0.34124012,  0.75488842],\n",
       "       [ 0.07159735,  0.77451529],\n",
       "       [ 0.94636011,  0.78701691],\n",
       "       [ 0.81656162,  0.79046895],\n",
       "       [ 0.81040828,  0.79120473],\n",
       "       [ 0.37345563,  0.79248378],\n",
       "       [ 0.27071096,  0.80927623],\n",
       "       [ 0.88762585,  0.83594971],\n",
       "       [ 0.85329763,  0.85519832],\n",
       "       [ 0.09985592,  0.85591995],\n",
       "       [ 0.12784339,  0.86145301],\n",
       "       [ 0.79924637,  0.87471398],\n",
       "       [ 0.17130699,  0.90090555],\n",
       "       [ 0.71949026,  0.90777896],\n",
       "       [ 0.58615788,  0.91062249],\n",
       "       [ 0.21832913,  0.91553868],\n",
       "       [ 0.74814291,  0.91584807],\n",
       "       [ 0.90041107,  0.93174501],\n",
       "       [ 0.65340085,  0.93774178],\n",
       "       [ 0.69805797,  0.96562358],\n",
       "       [ 0.3984782 ,  0.96619787],\n",
       "       [ 0.53337127,  0.96935042],\n",
       "       [ 0.9904141 ,  0.97264793],\n",
       "       [ 0.89275099,  0.99987134]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs=pairs[pairs[:, 1].argsort()]\n",
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pairs[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.97554321,  0.91683535,  0.11753879,  0.45717413,  0.74969962,\n",
       "        0.94523225,  0.99555302,  0.01933249,  0.41113054,  0.59465664,\n",
       "        0.27591197,  0.91304535,  0.64690736,  0.68787272,  0.36680882,\n",
       "        0.33992657,  0.90786571,  0.10580314,  0.90220203,  0.65804783,\n",
       "        0.95897061,  0.31340933,  0.14756861,  0.30416718,  0.23546181,\n",
       "        0.65932062,  0.13957594,  0.1443516 ,  0.65247316,  0.26953218,\n",
       "        0.22617551,  0.23636302,  0.55005082,  0.59398654,  0.15303398,\n",
       "        0.13855739,  0.24951643,  0.95925203,  0.09595789,  0.86138512,\n",
       "        0.90554072,  0.46697896,  0.15658305,  0.87998658,  0.74232022,\n",
       "        0.68554716,  0.39422025,  0.97286209,  0.83094588,  0.02712601,\n",
       "        0.08593361,  0.94451753,  0.58640828,  0.37961668,  0.08721703,\n",
       "        0.08914476,  0.47316729,  0.64711205,  0.01988686,  0.10180174,\n",
       "        0.49691032,  0.14578997,  0.27326587,  0.74941262,  0.61375438,\n",
       "        0.66350068,  0.55691427,  0.05561784,  0.90143821,  0.00802643,\n",
       "        0.04801087,  0.71617131,  0.88950342,  0.57679289,  0.20049751,\n",
       "        0.73860371,  0.34124012,  0.07159735,  0.94636011,  0.81656162,\n",
       "        0.81040828,  0.37345563,  0.27071096,  0.88762585,  0.85329763,\n",
       "        0.09985592,  0.12784339,  0.79924637,  0.17130699,  0.71949026,\n",
       "        0.58615788,  0.21832913,  0.74814291,  0.90041107,  0.65340085,\n",
       "        0.69805797,  0.3984782 ,  0.53337127,  0.9904141 ,  0.89275099])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Automated estimation of the number of bins is not supported for weighted data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-92cd0fc9d021>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbin_means\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'fd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mhistogram\u001b[1;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[0;32m    679\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} not a valid estimator for bins\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             raise TypeError(\"Automated estimation of the number of \"\n\u001b[0m\u001b[0;32m    682\u001b[0m                             \"bins is not supported for weighted data\")\n\u001b[0;32m    683\u001b[0m         \u001b[1;31m# Make a reference to `a`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Automated estimation of the number of bins is not supported for weighted data"
     ]
    }
   ],
   "source": [
    "\n",
    "bin_means = (np.histogram(data, bins='fd', weights=data)[0] / np.histogram(data, bins='fd')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_size=7\n",
    "Number_of_bins=int(Y.size/cluster_size)\n",
    "Number_of_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.03565684,  0.11620999,  0.17995013,  0.25461722,  0.3246858 ,\n",
       "        0.38728502,  0.47355768,  0.54677879,  0.59195943,  0.66522404,\n",
       "        0.73769152,  0.82209195,  0.8965492 ,  0.96541166])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_means = (np.histogram(data, Number_of_bins, weights=data)[0] / np.histogram(data, Number_of_bins)[0])\n",
    "bin_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.081552575927668444"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(bin_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.098727772841276221"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.826034798321439"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(bin_means)/np.var(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=\"\"\"('etyr (arfas)','eyt euyt','hfhafhds, fdsjfgsd, dgfdg')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('etyr (arfas)','eyt euyt')\""
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{},{})'.format(test.split(',', 3)[0],test.split(',', 3)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('etyr (arfas)','eyt euyt')\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_2=\"\"\"('etyr (arfas)','eyt euyt','hfhafhds fdsjfgsd')\"\"\"\n",
    "'{},{})'.format(test_2.split(',', 3)[0],test_2.split(',', 3)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\numpy\\lib\\function_base.py:3162: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\numpy\\lib\\function_base.py:3163: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\Laure\\Anaconda3\\envs\\Brighway2\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    }
   ],
   "source": [
    "res_spr=stats.spearmanr([3,3,3,3,3,3,3],[3,4,36,5643,36,3,36])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_spr+567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('jhgh', 'ehgeh')}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(list(zip(['jhgh','ehgeh'],['ehgeh'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jhgh', 'ehgeh')]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(['jhgh','ehgeh'],['ehgeh']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fdgfd']"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets=[]\n",
    "sets.append('fdgfd')\n",
    "sets=list(set(sets))\n",
    "sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fdgfd', 'hfj']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sets.append('hfj')\n",
    "sets=list(set(sets))\n",
    "sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fdgfd', 'hfj']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
